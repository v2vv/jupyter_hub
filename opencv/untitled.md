
# 机器学习算法

机器学习算法（ML）的主要方法是基于神经进化（或神经进化）。这种机器学习形式使用进化算法，例如遗传算法 (GA) 来训练人工神经网络 (ANN)。


# 遗传算法详解（GA）

把那些总是爱走下坡路的袋鼠射杀，这就是遗传算法的精粹！）

https://blog.csdn.net/u010451580/article/details/51178225


# 损失函数 
  
1. 损失函数计算单个训练样本的误差，
2. 代价函数是整个训练集的损失函数的平均。但一般来说对两者不做过多区分，以下我们统称为损失函数。
3. 损失函数用于测量模型性能以及实际值 y_i 和预测值 y-hat 之间的不一致性。模型性能随着损失函数值的降低而增加。


# 权重

W

# 偏置

p

# 激活函数

# 感知器

输出w · x+b为0或1
与⾮⻔的例⼦显⽰了我们可以⽤感知器来计算简单的逻辑功能。实际上，我们完全能⽤感知
器⽹络来计算任何逻辑功能。原因是与⾮⻔是通⽤运算，那样，我们能在多个与⾮⻔之上构建
出任何运算。

# S 型神经元
σ(w · x+b)
- 当 z = w · x + b 很⼤并且为正，S 型神经元的输出近似为 1
- 当 z = w · x + b是⼀个很⼤的负数，S 型神经元的⾏为也⾮常近似⼀个感知器。
- 只有在 w · x + b 取中间值时，和感知器模型有⽐较⼤的偏离。
- σ 有时被称为逻辑函数，⽽这种新的神经元类型被称为逻辑神经元。
- 如果 σ 实际是个阶跃函数，既然输出会依赖于 w · x + b 是正数还是负数2，那么 S 型神经元会成为⼀个感知器。
- σ 函数的平滑特性，正是关键因素，⽽不是其细部形式。σ 的平滑意味着权重和偏置的微⼩变化，即 ∆wj 和 ∆b，会从神经元产⽣⼀个微⼩的输出变化 ∆output。
- S 型神经元不仅仅输出 0 或 1。它可以输出 0 和 1 之间的任何实数
- 约定任何⾄少为 0.5 的输出为表⽰“这是⼀个 9”，⽽其它⼩于 0.5 的输出为表⽰“不是⼀个 9”。当我们正在使⽤这样的约定时，我总会清楚地提出来，这样就不会引起混淆。
S 型函数
sigmoid

# 向前传播算法

# 向后传播算法

# 反向传播算法

# 梯度下降法


# 神经网络

前馈神经网络

循环神经网络

训练神经网络

1. 设计一个神经网络时，输入层与输出层的节点数往往是固定的，中间层则可以自由指定；
2. 神经网络结构图中的拓扑与箭头代表着预测过程时数据的流向，跟训练时的数据流有一定的区别；
3. 结构图里的关键不是圆圈（代表“神经元”），而是连接线（代表“神经元”之间的连接）。每个连接线对应一个不同的权重（其值称为权值），这是需要训练得到的。  

[用循环神经网络创作音乐](https://www.danieldjohnson.com/2015/08/03/composing-music-with-recurrent-neural-networks/)

[《深度学习》](https://github.com/exacity/deeplearningbook-chinese)

[神经网络与深度学习](http://neuralnetworksanddeeplearning.com/about.html)

[Christopher Olah的博客](http://colah.github.io/)

[吴恩达的机器学习课程](https://www.coursera.org/specializations/deep-learning)

[程序员的实用深度学习](https://course.fast.ai/)

[3Blue1Brow_Youtube](https://www.youtube.com/watch?v=aircAruvnKk&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&ab_channel=3Blue1Brown)

输入层


隐藏层

“既⾮输⼊也⾮输出”。

输出层




# 计算机视觉 CV

# 神经网络和深度学习

- 教计算机识别手写数字的问题。使用传统的编程方法很难解决这个问题。

  什么是神经网络？首先，我将解释一种称为感知器的人工神经元。
  
  
